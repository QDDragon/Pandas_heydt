{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Concatenating data in multiple pandas objects\n",
    "Merging data in multiple pandas objects\n",
    "How to control the type of join used in a merge\n",
    "Pivoting data to and from values and indexes\n",
    "Stacking and unstacking data\n",
    "Melting data to and from wide and long format\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 60)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "dtype: int32\n",
      "0    5\n",
      "1    6\n",
      "2    7\n",
      "dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "0    5\n",
       "1    6\n",
       "2    7\n",
       "dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat 2 series\n",
    "s1 = pd.Series (np.arange(0,3))\n",
    "print(s1)\n",
    "s2 = pd.Series(np.arange(5,8))\n",
    "print(s2)\n",
    "pd.concat([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  3  4  5\n",
      "2  6  7  8\n",
      "    a   b   c\n",
      "0   9  10  11\n",
      "1  12  13  14\n",
      "2  15  16  17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    a   b   c\n",
       "0   0   1   2\n",
       "1   3   4   5\n",
       "2   6   7   8\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat 2 DataFrame\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3,3),\n",
    "                   columns=['a','b','c'])\n",
    "print(df1)\n",
    "df2 = pd.DataFrame(np.arange(9,18).reshape(3,3),\n",
    "                   columns=['a','b','c'])\n",
    "print(df2)\n",
    "pd.concat([df1, df2]) #default function: rows being appended in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  3  4  5\n",
      "2  6  7  8\n",
      "    a   b   d\n",
      "0   9  10  11\n",
      "1  12  13  14\n",
      "2  15  16  17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    a   b    c     d\n",
       "0   0   1  2.0   NaN\n",
       "1   3   4  5.0   NaN\n",
       "2   6   7  8.0   NaN\n",
       "0   9  10  NaN  11.0\n",
       "1  12  13  NaN  14.0\n",
       "2  15  16  NaN  17.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas will insert NaN values if a column in the result doesnot exist \n",
    "# in the DataFrame object currently being processed\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3,3),\n",
    "                   columns=['a','b','c'])\n",
    "print(df1)\n",
    "df2 = pd.DataFrame(np.arange(9,18).reshape(3,3),\n",
    "                   columns=['a','b','d'])\n",
    "print(df2)\n",
    "pd.concat([df1, df2]) #NaN's will be filled in for the d column for df1 and c column for df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  3  4  5\n",
      "2  6  7  8\n",
      "\n",
      "\n",
      "    a   b   c\n",
      "0   9  10  11\n",
      "1  12  13  14\n",
      "2  15  16  17\n",
      "\n",
      "\n",
      "        a   b   c\n",
      "df1 0   0   1   2\n",
      "    1   3   4   5\n",
      "    2   6   7   8\n",
      "df2 0   9  10  11\n",
      "    1  12  13  14\n",
      "    2  15  16  17\n",
      "\n",
      "\n",
      "    a   b   c\n",
      "0   9  10  11\n",
      "1  12  13  14\n",
      "2  15  16  17\n",
      "\n",
      "\n",
      "a    15\n",
      "b    16\n",
      "c    17\n",
      "Name: 2, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n",
    "print('\\n')\n",
    "print(df2)\n",
    "print('\\n')\n",
    "c = pd.concat([df1, df2], keys=['df1','df2'])\n",
    "print(c)\n",
    "print('\\n')\n",
    "print(c.loc['df2']) # extract the data originating from the fist ('df1') or second ('df2')\n",
    "print('\\n')\n",
    "print(c.loc['df2'].loc[2]) #access index 'df2' then access index '2' (hierarchical index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b    c     a     b\n",
       "0  0.0  1.0  2.0   NaN   NaN\n",
       "1  3.0  4.0  5.0   NaN   NaN\n",
       "2  6.0  7.0  8.0  20.0  21.0\n",
       "3  NaN  NaN  NaN  22.0  23.0\n",
       "4  NaN  NaN  NaN  24.0  25.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switching axes of alignment\n",
    "    # concat to row not column as above \n",
    "    # => can cause duplicate columns: (two column 'a' and two column 'c')\n",
    "pd.concat([df1, df2], axis = 1) \n",
    "df3 = pd.DataFrame(np.arange(20, 26).reshape(3,2),\n",
    "                   columns=['a','b'],\n",
    "                   index=[2, 3, 4])\n",
    "    # concat them. Alignment is along row labels\n",
    "    # columns first from df1 and then df3, with duplicates.\n",
    "    # NaN filled in where those columns do not exist in the source\n",
    "pd.concat([df1, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  3  4  5\n",
      "2  6  7  8\n",
      "\n",
      "\n",
      "    a   b\n",
      "2  20  21\n",
      "3  22  23\n",
      "4  24  25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   a  b  c   a   b\n",
       "2  6  7  8  20  21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A default concatenation actually performs an outer join operation along the index labels on\n",
    "the axis opposite of the concatenation (the rows index). This makes the resulting set of\n",
    "labels similar to having performed a union of those labels.\n",
    "\n",
    "The type of join can be changed to an inner join by specifying \"join\" = \"inner\" as a\n",
    "parameter. The inner join then logically performs an intersection of labels instead of a\n",
    "union. The following demonstrates this and results in a single row, because \u0014 is the only\n",
    "row index label in common:\n",
    "\"\"\"\n",
    "\n",
    "#do an inner joint instead of outer join as default, result in one row\n",
    "print(df1)\n",
    "print('\\n')\n",
    "print(df3)\n",
    "pd.concat([df1, df3], axis=1, join='inner') #only row index '2' is in common, remove all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  df1       df2        \n",
       "    a  b  c   a   b   c\n",
       "0   0  1  2   9  10  11\n",
       "1   3  4  5  12  13  14\n",
       "2   6  7  8  15  16  17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label group of data along the columns using keys parameter\n",
    "df = pd.concat([df1, df2],\n",
    "               axis=1,\n",
    "               keys=['df1','df2']) # 'df1' and 'df2' are column name/ key hirerache\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Chon tat ca cac hang; cot co key 'df2'\n",
    "df.loc[:, 'df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending versus concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  3  4  5\n",
      "2  6  7  8\n",
      "    a   b   d\n",
      "0   9  10  11\n",
      "1  12  13  14\n",
      "2  15  16  17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    a   b    c     d\n",
       "0   0   1  2.0   NaN\n",
       "1   3   4  5.0   NaN\n",
       "2   6   7  8.0   NaN\n",
       "0   9  10  NaN  11.0\n",
       "1  12  13  NaN  14.0\n",
       "2  15  16  NaN  17.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append does a concatenate along axis = 0; \n",
    "#duplicate row index labels can results\n",
    "print(df1)\n",
    "print(df2)\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignoring the index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b    c     d\n",
       "0   0   1  2.0   NaN\n",
       "1   3   4  5.0   NaN\n",
       "2   6   7  8.0   NaN\n",
       "3   9  10  NaN  11.0\n",
       "4  12  13  NaN  14.0\n",
       "5  15  16  NaN  17.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and joining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CustomerID': [10, 11],\n",
       " 'Name': ['Mike', 'Marcia'],\n",
       " 'Address': ['Address for Mike', 'Address for Marcia']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are our customers\n",
    "customers = {'CustomerID': [10, 11],\n",
    "             'Name': ['Mike', 'Marcia'],\n",
    "             'Address': ['Address for Mike',\n",
    "                         'Address for Marcia']}\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address\n",
       "0          10    Mike    Address for Mike\n",
       "1          11  Marcia  Address for Marcia"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = pd.DataFrame(customers)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID   OrderDate\n",
       "0          10  2014-12-01\n",
       "1          11  2014-12-01\n",
       "2          10  2014-12-01"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # and these are the orders made by our customers; they are related to customers by CustomerID\n",
    "orders = {'CustomerID': [10, 11, 10],\n",
    "          'OrderDate': [date(2014, 12, 1),\n",
    "                        date(2014, 12, 1),\n",
    "                        date(2014, 12, 1)]}\n",
    "orders = pd.DataFrame(orders)\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address   OrderDate\n",
       "0          10    Mike    Address for Mike  2014-12-01\n",
       "1          10    Mike    Address for Mike  2014-12-01\n",
       "2          11  Marcia  Address for Marcia  2014-12-01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge customers and orders so we can ship the items\n",
    "customers.merge(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Under the hood of merge:\n",
    "1. It determines the columns in both DVTUPNFST and PSEFST with common labels. \n",
    "These columns are treated as the keys to perform the join.\n",
    "2. It creates a new %BUB'SBNF, whose columns are the labels from the keys\n",
    "identified in step 1, followed by all the non-key labels from both the objects.\n",
    "3. It matches values in the key columns of both %BUB'SBNF objects.\n",
    "4. It then creates a row in the result for each set of matching labels.\n",
    "5. It then copies the data from those matching rows from each source object into\n",
    "that respective row and columns of the result.\n",
    "6. It assigns a new *OU\u0018\u0016*OEFY to the result.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2  lval1\n",
      "0    a    x      0\n",
      "1    b    y      1\n",
      "2    c    z      2\n",
      "  key1 key2  rval1\n",
      "1    a    x      6\n",
      "2    b    a      7\n",
      "3    c    z      8\n"
     ]
    }
   ],
   "source": [
    "#Merging and joining data _ JOIN\n",
    "# data to be used in the remainder of this section's examples\n",
    "left_data = {'key1': ['a', 'b', 'c'],\n",
    "            'key2': ['x', 'y', 'z'],\n",
    "            'lval1': [ 0, 1, 2]}\n",
    "right_data = {'key1': ['a', 'b', 'c'],\n",
    "              'key2': ['x', 'a', 'z'],\n",
    "              'rval1': [ 6, 7, 8 ]}\n",
    "left = pd.DataFrame(left_data, index=[0, 1, 2])\n",
    "right = pd.DataFrame(right_data, index=[1, 2, 3])\n",
    "print(left)\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge without specifying columns to merge; \n",
    "    #this will implicitly merge on all common columns\n",
    "#left and right have the same a - x and c - z row. \n",
    "    #so, merge will combine the row have same a - x and c - z in two DataFramesematics\n",
    "left.merge(right) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2_x  lval1 key2_y  rval1\n",
       "0    a      x      0      x      6\n",
       "1    b      y      1      a      7\n",
       "2    c      z      2      z      8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge using an explicit column; \n",
    "    # on needs the value to be in both DataFrame objects: column of 'key1'\n",
    "left.merge(right, on='key1') #in here key1 will be the 'key point' to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # merge explicitly using two columns\n",
    "    # #the same element in key1 and key2 are the key point to merge\n",
    "left.merge(right, on=['key1', 'key2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_x key2_x  lval1 key1_y key2_y  rval1\n",
       "1      b      y      1      a      x      6\n",
       "2      c      z      2      b      a      7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on the row indices of both matrices\n",
    "    # left and right have the same index 1, 2 so they are key point to merge\n",
    "pd.merge(left, right, left_index=True, right_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the join semantics (ngữ nghĩa học) of a merge operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The default type of join performed by pd.merge() is an inner join. \n",
    "To use another join method, specify the join type using the how parameter of the pd.merge()\n",
    "function (or the .merge() method). The valid options are:\n",
    "    inner: This is the intersection of keys from both DataFrame objects\n",
    "    outer: This is the union of keys from both DataFrame objects\n",
    "    left: This only uses keys from the left DataFrame\n",
    "    right: This only uses keys from the right DataFrame\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x    0.0    6.0\n",
       "1    b    y    1.0    NaN\n",
       "2    c    z    2.0    8.0\n",
       "3    b    a    NaN    7.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    # NaN filled in the unmatched  portion. The following code demonstrates an outer join:\n",
    "    # outer join, merges all matched data of right to left, \n",
    "        # and fills unmatched items with NaN (ko tinh index)\n",
    "left.merge(right, how='outer') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting data to and from value and indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading\n",
       "0          0    X      0.0\n",
       "1          0    Y      0.5\n",
       "2          0    Z      1.0\n",
       "3          1    X      0.1\n",
       "4          1    Y      0.4\n",
       "..       ...  ...      ...\n",
       "7          2    Y      0.3\n",
       "8          2    Z      0.8\n",
       "9          3    X      0.3\n",
       "10         3    Y      0.2\n",
       "11         3    Z      0.7\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" lua chon data tu value trong mot cot; vi du 1 cot co value X, Y, Z. dung .pivot() de xep lai cac value; pivot a level of column labels to row index (bien ca gia tri trong cot interval thanh row index ) \"\"\"\n",
    "\n",
    "sensor_readings = pd.read_csv(\"accel.csv\")\n",
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "what if you want to know the values for all axes at a given time and not\n",
    "just the Y axis. To do this, you can perform a selection for each value of the axis, but that is\n",
    "repetitive code and does not handle the scenario of new axis values being inserted into\n",
    "DataFrame without a change to the code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "axis        X    Y    Z\n",
       "interval               \n",
       "0         0.0  0.5  1.0\n",
       "1         0.1  0.4  0.9\n",
       "2         0.2  0.3  0.8\n",
       "3         0.3  0.2  0.7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To convert to this form, use the DataFrame objects' pivot function:\n",
    "sensor_readings.pivot(index='interval', \n",
    "        #dua cac gia tri trong interval thanh index (0, 1, 2...)\n",
    "                      columns='axis', \n",
    "        #lay cac gia tri (X, Y, Z, X, Y, Z,...) trong cot 'axis' thanh 3 colum label (X, Y, Z)\n",
    "                      values='reading',) \n",
    "        #doc cac gia tri trong cot 'reading' thanh value cho 3 cot (X, Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking and unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " The process of stacking pivots (quay, xoay truc) a level of column labels to the row index. \n",
    " Unstacking performs the opposite, that is, \n",
    " pivoting a level of the row index into the column index.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One of the differences between stacking/unstacking and performing a pivot is that unlike\n",
    "pivots, the stack and unstack functions are able to pivot specific levels of a hierarchical\n",
    "index\n",
    "\n",
    "where a pivot retains the same number of levels on an index, a stack and\n",
    "unstack always increases the levels on the index of one of the axes (columns for unstacking\n",
    "and rows for stacking) and decrease the levels on the other axis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a  b\n",
       "two  1  3\n",
       "one  2  4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking using non-hierarchical indexes\n",
    "df = pd.DataFrame({'a': [1,2],\n",
    "                   'b' : [3, 4]},\n",
    "                  index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two  a    1\n",
       "     b    3\n",
       "one  a    2\n",
       "     b    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked1 = df.stack() \n",
    "#push the column (a) to another level of index; the result is a Series where \n",
    "    #value are looked up through a multi-index\n",
    "stacked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked1[('one','a')] #to access mulitple-index we have to pass a tuple\n",
    "stacked1[('one','b')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unstacking using hierarchical indexes\n",
    "\"\"\"\n",
    "Unstacking will perform a similar operation in the opposite direction, by moving a level of\n",
    "the row index into a level of the column's axis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    interval axis  reading\n",
      "0          0    X      0.0\n",
      "1          0    Y      0.5\n",
      "2          0    Z      1.0\n",
      "3          1    X      0.1\n",
      "4          1    Y      0.4\n",
      "..       ...  ...      ...\n",
      "7          2    Y      0.3\n",
      "8          2    Z      0.8\n",
      "9          3    X      0.3\n",
      "10         3    Y      0.2\n",
      "11         3    Z      0.7\n",
      "\n",
      "[12 rows x 3 columns]\n",
      "    interval axis  reading\n",
      "0          0    X      0.0\n",
      "1          0    Y      0.5\n",
      "2          0    Z      1.0\n",
      "3          1    X      0.1\n",
      "4          1    Y      0.4\n",
      "..       ...  ...      ...\n",
      "7          2    Y      0.3\n",
      "8          2    Z      0.8\n",
      "9          3    X      0.3\n",
      "10         3    Y      0.2\n",
      "11         3    Z      0.7\n",
      "\n",
      "[12 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# make two copies of the sensor data, one for each user\n",
    "user1 = sensor_readings.copy()\n",
    "print(user1)\n",
    "user2 = sensor_readings.copy()\n",
    "print(user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    interval axis  reading     who\n",
      "0          0    X      0.0  Mickey\n",
      "1          0    Y      0.5  Mickey\n",
      "2          0    Z      1.0  Mickey\n",
      "3          1    X      0.1  Mickey\n",
      "4          1    Y      0.4  Mickey\n",
      "..       ...  ...      ...     ...\n",
      "7          2    Y      0.3  Mickey\n",
      "8          2    Z      0.8  Mickey\n",
      "9          3    X      0.3  Mickey\n",
      "10         3    Y      0.2  Mickey\n",
      "11         3    Z      0.7  Mickey\n",
      "\n",
      "[12 rows x 4 columns]\n",
      "    interval axis  reading  who\n",
      "0          0    X      0.0  TOM\n",
      "1          0    Y     50.0  TOM\n",
      "2          0    Z    100.0  TOM\n",
      "3          1    X     10.0  TOM\n",
      "4          1    Y     40.0  TOM\n",
      "..       ...  ...      ...  ...\n",
      "7          2    Y     30.0  TOM\n",
      "8          2    Z     80.0  TOM\n",
      "9          3    X     30.0  TOM\n",
      "10         3    Y     20.0  TOM\n",
      "11         3    Z     70.0  TOM\n",
      "\n",
      "[12 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# add names to the two copies\n",
    "user1['who'] = 'Mickey'\n",
    "user2['who'] = 'TOM'\n",
    "print(user1)\n",
    "print(user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demonstration, lets scale user2's readings\n",
    "user2['reading'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      reading\n",
       "who    interval axis         \n",
       "Mickey 0        X         0.0\n",
       "                Y         0.5\n",
       "                Z         1.0\n",
       "       1        X         0.1\n",
       "                Y         0.4\n",
       "...                       ...\n",
       "TOM    2        Y      3000.0\n",
       "                Z      8000.0\n",
       "       3        X      3000.0\n",
       "                Y      2000.0\n",
       "                Z      7000.0\n",
       "\n",
       "[24 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # and reorganize this to have a hierarchical row index\n",
    "multi_user_sensor_data = pd.concat([user1, user2]).set_index(['who', 'interval', 'axis'])\n",
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               reading\n",
       "interval axis         \n",
       "0        X         0.0\n",
       "         Y         0.5\n",
       "         Z         1.0\n",
       "1        X         0.1\n",
       "         Y         0.4\n",
       "...                ...\n",
       "2        Y         0.3\n",
       "         Z         0.8\n",
       "3        X         0.3\n",
       "         Y         0.2\n",
       "         Z         0.7\n",
       "\n",
       "[12 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup user data for Mike using just the index\n",
    "multi_user_sensor_data.loc['Mickey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             reading\n",
       "who    axis         \n",
       "Mickey X         0.1\n",
       "       Y         0.4\n",
       "       Z         0.9\n",
       "TOM    X      1000.0\n",
       "       Y      4000.0\n",
       "       Z      9000.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readings for all users and axes at interval 1\n",
    "multi_user_sensor_data.xs(1, level='interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Unstacking will move the last level of the row index into a new level of the column index,\n",
    "resulting in columns having MultiIndex. The following demonstrates the last level of this\n",
    "unstacking (the axis level of the index)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                reading                 \n",
       "axis                  X       Y        Z\n",
       "who    interval                         \n",
       "Mickey 0            0.0     0.5      1.0\n",
       "       1            0.1     0.4      0.9\n",
       "       2            0.2     0.3      0.8\n",
       "       3            0.3     0.2      0.7\n",
       "TOM    0            0.0  5000.0  10000.0\n",
       "       1         1000.0  4000.0   9000.0\n",
       "       2         2000.0  3000.0   8000.0\n",
       "       3         3000.0  2000.0   7000.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack the axis level (latest level of the index)\n",
    "multi_user_sensor_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              reading         \n",
       "who            Mickey      TOM\n",
       "interval axis                 \n",
       "0        X        0.0      0.0\n",
       "         Y        0.5   5000.0\n",
       "         Z        1.0  10000.0\n",
       "1        X        0.1   1000.0\n",
       "         Y        0.4   4000.0\n",
       "...               ...      ...\n",
       "2        Y        0.3   3000.0\n",
       "         Z        0.8   8000.0\n",
       "3        X        0.3   3000.0\n",
       "         Y        0.2   2000.0\n",
       "         Z        0.7   7000.0\n",
       "\n",
       "[12 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To unstack a different level, use the level parameter.\n",
    "    # The following code unstacks the first level (level = 0)\n",
    "multi_user_sensor_data.unstack(level=0) # column 'who': level 0 become row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         reading                                   \n",
       "who       Mickey               TOM                 \n",
       "axis           X    Y    Z       X       Y        Z\n",
       "interval                                           \n",
       "0            0.0  0.5  1.0     0.0  5000.0  10000.0\n",
       "1            0.1  0.4  0.9  1000.0  4000.0   9000.0\n",
       "2            0.2  0.3  0.8  2000.0  3000.0   8000.0\n",
       "3            0.3  0.2  0.7  3000.0  2000.0   7000.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple levels can be unstacked simultaneously by passing a list of the levels to .unstack()\n",
    "    # Unstack level 0 'who' and level 2 'axis'\n",
    "unstacked = multi_user_sensor_data.unstack(['who', 'axis']) \n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                reading                 \n",
       "axis                  X       Y        Z\n",
       "interval who                            \n",
       "0        Mickey     0.0     0.5      1.0\n",
       "         TOM        0.0  5000.0  10000.0\n",
       "1        Mickey     0.1     0.4      0.9\n",
       "         TOM     1000.0  4000.0   9000.0\n",
       "2        Mickey     0.2     0.3      0.8\n",
       "         TOM     2000.0  3000.0   8000.0\n",
       "3        Mickey     0.3     0.2      0.7\n",
       "         TOM     3000.0  2000.0   7000.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  we can restack this data. \n",
    "#The following code will stack the who level of the column back into the row index:\n",
    "unstacked.stack(level='who') #we can of course stack what we have unstacked this re-stacks who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note:\n",
    "    stacking and unstacking always move the levels into the last levels of the other index \n",
    "    => unstack may don't make the result come back the same as the origin\n",
    "    pivit, stack, unstack doesn't change data, it just is reorganized\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting data to and from long and wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "melting is the process of reshaping a DataFrame object into a format\n",
    "where two or more columns, referred to as variable and value, \n",
    "are created by unpivoting column labels in the variable column, and then moving the data from these\n",
    "columns into the appropriate location in the value column\n",
    "\n",
    "changing a DataFrame object\n",
    "from wide format to long format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name  Height  Weight\n",
       "0    Mike     6.1     220\n",
       "1  Mikael     6.0     185"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will demonstrate melting with this DataFrame\n",
    "data = pd.DataFrame({'Name' : ['Mike', 'Mikael'],\n",
    "                     'Height' : [6.1, 6.0],\n",
    "                     'Weight' : [220, 185]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name variable  value\n",
       "0    Mike   Height    6.1\n",
       "1  Mikael   Height    6.0\n",
       "2    Mike   Weight  220.0\n",
       "3  Mikael   Weight  185.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melt it, use Name as the id's,\n",
    "    # Height and Weight columns as the variables\n",
    "pd.melt(data,\n",
    "        # Using Name column as identifier column\n",
    "        id_vars=['Name'],\n",
    "        # Height and Weight columns as measured variables; \n",
    "        # Height and Weight column un-pivoted into the variable column\n",
    "        value_vars=['Height', 'Weight'])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance benefits of stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"It can be shown that stacked\n",
    "data is more efficient than using lookup through a single level index and then a column\n",
    "lookup, or even compared to an \u0010JMPD lookup that specifies the row and column by\n",
    "location\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
